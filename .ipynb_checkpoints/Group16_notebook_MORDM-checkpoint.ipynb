{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ema_workbench\n",
      "  Using cached ema_workbench-2.4.1-py3-none-any.whl (24.7 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.25.0-cp311-cp311-win_amd64.whl (15.0 MB)\n",
      "     --------------------------------------- 15.0/15.0 MB 36.4 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.2-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "     --------------------------------------- 10.6/10.6 MB 36.4 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp311-cp311-win_amd64.whl (8.3 MB)\n",
      "Collecting salib>=1.4.6\n",
      "  Using cached salib-1.4.7-py3-none-any.whl (757 kB)\n",
      "Collecting platypus-opt\n",
      "  Using cached Platypus_Opt-1.1.0-py3-none-any.whl (76 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.1-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 34.5 MB/s eta 0:00:00\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Collecting scipy>=1.7.3\n",
      "  Using cached scipy-1.10.1-cp311-cp311-win_amd64.whl (42.2 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp311-cp311-win_amd64.whl (470 kB)\n",
      "     ---------------------------------------- 470.9/470.9 kB ? eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.40.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 30.7 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sisko\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->ema_workbench) (23.1)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.5.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.1.0-py3-none-any.whl (102 kB)\n",
      "     ---------------------------------------- 102.6/102.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sisko\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->ema_workbench) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sisko\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->ema_workbench) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\sisko\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from patsy>=0.5.2->statsmodels->ema_workbench) (1.16.0)\n",
      "Collecting dill>=0.3.6\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Installing collected packages: pytz, tzdata, tqdm, threadpoolctl, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, dill, cycler, scipy, platypus-opt, patsy, pandas, multiprocess, contourpy, statsmodels, scikit-learn, matplotlib, seaborn, salib, ema_workbench\n",
      "Successfully installed contourpy-1.1.0 cycler-0.11.0 dill-0.3.6 ema_workbench-2.4.1 fonttools-4.40.0 joblib-1.2.0 kiwisolver-1.4.4 matplotlib-3.7.1 multiprocess-0.70.14 numpy-1.25.0 pandas-2.0.2 patsy-0.5.3 pillow-9.5.0 platypus-opt-1.1.0 pyparsing-3.1.0 pytz-2023.3 salib-1.4.7 scikit-learn-1.2.2 scipy-1.10.1 seaborn-0.12.2 statsmodels-0.14.0 threadpoolctl-3.1.0 tqdm-4.65.0 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\Sisko\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Sisko\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'C:\\Users\\Sisko\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script salib.exe is installed in 'C:\\Users\\Sisko\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install ema_workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T20:58:03.053514Z",
     "start_time": "2023-06-20T20:58:02.896133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sisko\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:58: UserWarning: ipyparallel not installed - IpyparalleEvaluator not available\n",
      "  warnings.warn(\"ipyparallel not installed - IpyparalleEvaluator not available\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Instantiate model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdike_model_function\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DikeNetwork, sum_over\n\u001b[0;32m     25\u001b[0m dike_model \u001b[38;5;241m=\u001b[39m Model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdikesnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, function\u001b[38;5;241m=\u001b[39mDikeNetwork(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_metrics, make_scenario, calculate_metrics\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\final assignment\\model\\dike_model_function.py:13\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mema_workbench\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ema_logging\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuns_generate_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_network\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuns_dikes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lookuplin, dikefailure, init_node\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuns_economy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cost_fun, discount, cost_evacuation\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\final assignment\\model\\funs_generate_network.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuns_dikes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lookuplin  \u001b[38;5;66;03m# @UnresolvedImport\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "#Some initial declarations and imports\n",
    "from ema_workbench import (\n",
    "    Model,\n",
    "    CategoricalParameter,\n",
    "    ScalarOutcome,\n",
    "    IntegerParameter,\n",
    "    RealParameter,\n",
    "    Policy,\n",
    "    Scenario,\n",
    "    MultiprocessingEvaluator,\n",
    "    SequentialEvaluator,\n",
    "    Samplers,\n",
    "    ema_logging\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#Instantiate model\n",
    "from model.dike_model_function import DikeNetwork, sum_over\n",
    "dike_model = Model(\"dikesnet\", function=DikeNetwork(1))\n",
    "\n",
    "from vis import plot_metrics, make_scenario, calculate_metrics\n",
    "\n",
    "from ema_workbench.analysis import prim\n",
    "from ema_workbench.analysis import dimensional_stacking\n",
    "from ema_workbench.analysis.scenario_discovery_util import RuleInductionType\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.em_framework.optimization import (HypervolumeMetric,\n",
    "                                                     EpsilonProgress,\n",
    "                                                     epsilon_nondominated,\n",
    "                                                     to_problem,\n",
    "                                                     ArchiveLogger)\n",
    "\n",
    "\n",
    "from ema_workbench import Constraint\n",
    "scenario_specs = [{'name': 'Worst case 1a, Dike 1 sterk', 'Bmax': 175, 'Brate': 1.5,\n",
    "                       'pfails': [1, 0.5, 0.5, 0.5, 0.5],\n",
    "                  'discount_rate': 3.5, 'ID_flood_wave_shape': 4},\n",
    "                      {'name': 'Worst case 1b, Dike 3 faalt', 'Bmax': 175, 'Brate': 1.5,\n",
    "                       'pfails': [0, 0.5, 0, 0.5, 0.5],\n",
    "                  'discount_rate': 3.5, 'ID_flood_wave_shape': 4},\n",
    "                      {'name': 'Worst case 1c, uit scenario discovery', 'Bmax': 175, 'Brate': 1.5,\n",
    "                       'pfails': [1, 0.5, 0, 0.5, 0.5],\n",
    "                  'discount_rate': 3.5, 'ID_flood_wave_shape': 4},\n",
    "                      {'name': 'worst case 2 duur', 'Bmax': 175, 'Brate': 1.5,\n",
    "                       'pfails': [0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                  'discount_rate': 1.5, 'ID_flood_wave_shape': 4},\n",
    "                      {'name': 'worst worst case', 'Bmax': 175, 'Brate': 1.5,\n",
    "                       'pfails': [1, 0.5, 0, 0.5, 0.5],\n",
    "                  'discount_rate': 1.5, 'ID_flood_wave_shape': 4}, ]\n",
    "ref_scenarios = []\n",
    "for spec in scenario_specs:\n",
    "    ref_scenarios.append(make_scenario(**spec))\n",
    "\n",
    "constraint_names =  ['A.1_Expected Number of Deaths',\n",
    "                            'A.2_Expected Number of Deaths',\n",
    "                            'A.3_Expected Number of Deaths',\n",
    "                            'A.4_Expected Number of Deaths',\n",
    "                            'A.5_Expected Number of Deaths']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem formulation\n",
    "\n",
    "A problem formulation consists of three things. Uncertainties and levers / policies and outcomes. Our problem formulation uses the configuration of standard formulation 3.\n",
    "### Uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T20:58:03.069190Z",
     "start_time": "2023-06-20T20:58:03.047179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CategoricalParameter('discount rate 0', [0, 1, 2, 3]),\n",
       " IntegerParameter('A.0_ID flood wave shape', 0, 132, resolution=None, default=None, variable_name=['A.0_ID flood wave shape'], pff=False),\n",
       " RealParameter('A.1_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.1_Bmax'], pff=False),\n",
       " RealParameter('A.1_pfail', 0, 1, resolution=None, default=None, variable_name=['A.1_pfail'], pff=False),\n",
       " CategoricalParameter('A.1_Brate', [0, 1, 2]),\n",
       " RealParameter('A.2_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.2_Bmax'], pff=False),\n",
       " RealParameter('A.2_pfail', 0, 1, resolution=None, default=None, variable_name=['A.2_pfail'], pff=False),\n",
       " CategoricalParameter('A.2_Brate', [0, 1, 2]),\n",
       " RealParameter('A.3_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.3_Bmax'], pff=False),\n",
       " RealParameter('A.3_pfail', 0, 1, resolution=None, default=None, variable_name=['A.3_pfail'], pff=False),\n",
       " CategoricalParameter('A.3_Brate', [0, 1, 2]),\n",
       " RealParameter('A.4_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.4_Bmax'], pff=False),\n",
       " RealParameter('A.4_pfail', 0, 1, resolution=None, default=None, variable_name=['A.4_pfail'], pff=False),\n",
       " CategoricalParameter('A.4_Brate', [0, 1, 2]),\n",
       " RealParameter('A.5_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.5_Bmax'], pff=False),\n",
       " RealParameter('A.5_pfail', 0, 1, resolution=None, default=None, variable_name=['A.5_pfail'], pff=False),\n",
       " CategoricalParameter('A.5_Brate', [0, 1, 2])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncertainties and Levers:\n",
    "# Specify uncertainties range:\n",
    "Real_uncert = {\"Bmax\": [30, 350], \"pfail\": [0, 1]}  # m and [.]\n",
    "# breach growth rate [m/day]\n",
    "cat_uncert_loc = {\"Brate\": (1.0, 1.5, 10)}\n",
    "\n",
    "cat_uncert = {\n",
    "    f\"discount rate {n}\": (1.5, 2.5, 3.5, 4.5) for n in dike_model.function.planning_steps\n",
    "}\n",
    "\n",
    "Int_uncert = {\"A.0_ID flood wave shape\": [0, 132]}\n",
    "\n",
    "uncertainties = []\n",
    "levers = []\n",
    "\n",
    "for uncert_name in cat_uncert.keys():\n",
    "    categories = cat_uncert[uncert_name]\n",
    "    uncertainties.append(CategoricalParameter(uncert_name, categories))\n",
    "\n",
    "for uncert_name in Int_uncert.keys():\n",
    "    uncertainties.append(\n",
    "        IntegerParameter(\n",
    "            uncert_name, Int_uncert[uncert_name][0], Int_uncert[uncert_name][1]\n",
    "        )\n",
    "    )\n",
    "\n",
    "for dike in dike_model.function.dikelist:\n",
    "    # uncertainties in the form: locationName_uncertaintyName\n",
    "    for uncert_name in Real_uncert.keys():\n",
    "        name = f\"{dike}_{uncert_name}\"\n",
    "        lower, upper = Real_uncert[uncert_name]\n",
    "        uncertainties.append(RealParameter(name, lower, upper))\n",
    "\n",
    "    for uncert_name in cat_uncert_loc.keys():\n",
    "        name = f\"{dike}_{uncert_name}\"\n",
    "        categories = cat_uncert_loc[uncert_name]\n",
    "        uncertainties.append(CategoricalParameter(name, categories))\n",
    "\n",
    "problem = get_SALib_problem(uncertainties)\n",
    "dike_model.uncertainties = uncertainties\n",
    "uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### levers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T20:58:03.069190Z",
     "start_time": "2023-06-20T20:58:03.053514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IntegerParameter('0_RfR 0', 0, 1, resolution=None, default=None, variable_name=['0_RfR 0'], pff=False),\n",
       " IntegerParameter('1_RfR 0', 0, 1, resolution=None, default=None, variable_name=['1_RfR 0'], pff=False),\n",
       " IntegerParameter('2_RfR 0', 0, 1, resolution=None, default=None, variable_name=['2_RfR 0'], pff=False),\n",
       " IntegerParameter('3_RfR 0', 0, 1, resolution=None, default=None, variable_name=['3_RfR 0'], pff=False),\n",
       " IntegerParameter('4_RfR 0', 0, 1, resolution=None, default=None, variable_name=['4_RfR 0'], pff=False),\n",
       " IntegerParameter('EWS_DaysToThreat', 0, 4, resolution=None, default=None, variable_name=['EWS_DaysToThreat'], pff=False),\n",
       " IntegerParameter('A.1_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.1_DikeIncrease 0'], pff=False),\n",
       " IntegerParameter('A.2_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.2_DikeIncrease 0'], pff=False),\n",
       " IntegerParameter('A.3_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.3_DikeIncrease 0'], pff=False),\n",
       " IntegerParameter('A.4_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.4_DikeIncrease 0'], pff=False),\n",
       " IntegerParameter('A.5_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.5_DikeIncrease 0'], pff=False)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range of dike heightening:\n",
    "dike_lev = {\"DikeIncrease\": [0, 10]}  # dm\n",
    "\n",
    "# Series of five Room for the River projects:\n",
    "rfr_lev = [f\"{project_id}_RfR\" for project_id in range(0, 5)]\n",
    "\n",
    "# Time of warning: 0, 1, 2, 3, 4 days ahead from the flood\n",
    "EWS_lev = {\"EWS_DaysToThreat\": [0, 4]}  # days\n",
    "\n",
    "# RfR levers can be either 0 (not implemented) or 1 (implemented)\n",
    "for lev_name in rfr_lev:\n",
    "    for n in dike_model.function.planning_steps:\n",
    "        lev_name_ = f\"{lev_name} {n}\"\n",
    "        levers.append(IntegerParameter(lev_name_, 0, 1))\n",
    "\n",
    "# Early Warning System lever\n",
    "for lev_name in EWS_lev.keys():\n",
    "    levers.append(\n",
    "        IntegerParameter(lev_name, EWS_lev[lev_name][0], EWS_lev[lev_name][1])\n",
    "    )\n",
    "\n",
    "for dike in dike_model.function.dikelist:\n",
    "    # location-related levers in the form: locationName_leversName\n",
    "    for lev_name in dike_lev.keys():\n",
    "        for n in dike_model.function.planning_steps:\n",
    "            name = f\"{dike}_{lev_name} {n}\"\n",
    "            levers.append(\n",
    "                IntegerParameter(name, dike_lev[lev_name][0], dike_lev[lev_name][1])\n",
    "            )\n",
    "\n",
    "# load uncertainties and levers in dike_model:\n",
    "dike_model.levers = levers\n",
    "levers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T20:58:03.080745Z",
     "start_time": "2023-06-20T20:58:03.069190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScalarOutcome('A.1 Total Costs', variable_name=('A.1_Expected Annual Damage', 'A.1_Dike Investment Costs'), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.1_Expected Number of Deaths', variable_name=('A.1_Expected Number of Deaths',), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.2 Total Costs', variable_name=('A.2_Expected Annual Damage', 'A.2_Dike Investment Costs'), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.2_Expected Number of Deaths', variable_name=('A.2_Expected Number of Deaths',), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.3 Total Costs', variable_name=('A.3_Expected Annual Damage', 'A.3_Dike Investment Costs'), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.3_Expected Number of Deaths', variable_name=('A.3_Expected Number of Deaths',), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.4 Total Costs', variable_name=('A.4_Expected Annual Damage', 'A.4_Dike Investment Costs'), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.4_Expected Number of Deaths', variable_name=('A.4_Expected Number of Deaths',), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.5 Total Costs', variable_name=('A.5_Expected Annual Damage', 'A.5_Dike Investment Costs'), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('A.5_Expected Number of Deaths', variable_name=('A.5_Expected Number of Deaths',), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('RfR Total Costs', variable_name=('RfR Total Costs',), function=<function sum_over at 0x00000225B5BE9E40>),\n",
       " ScalarOutcome('Expected Evacuation Costs', variable_name=('Expected Evacuation Costs',), function=<function sum_over at 0x00000225B5BE9E40>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = []\n",
    "\n",
    "for dike in dike_model.function.dikelist:\n",
    "    cost_variables = []\n",
    "    for e in [\"Expected Annual Damage\", \"Dike Investment Costs\"]:\n",
    "        cost_variables.append(f\"{dike}_{e}\")\n",
    "\n",
    "    outcomes.append(\n",
    "        ScalarOutcome(\n",
    "            f\"{dike} Total Costs\",\n",
    "            variable_name=[var for var in cost_variables],\n",
    "            function=sum_over,\n",
    "            kind=ScalarOutcome.MINIMIZE,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    outcomes.append(\n",
    "        ScalarOutcome(\n",
    "            f\"{dike}_Expected Number of Deaths\",\n",
    "            variable_name=f\"{dike}_Expected Number of Deaths\",\n",
    "            function=sum_over,\n",
    "            kind=ScalarOutcome.MINIMIZE,\n",
    "        )\n",
    "    )\n",
    "\n",
    "outcomes.append(\n",
    "    ScalarOutcome(\n",
    "        \"RfR Total Costs\",\n",
    "        variable_name=\"RfR Total Costs\",\n",
    "        function=sum_over,\n",
    "    )\n",
    ")\n",
    "outcomes.append(\n",
    "    ScalarOutcome(\n",
    "        \"Expected Evacuation Costs\",\n",
    "        variable_name=\"Expected Evacuation Costs\",\n",
    "        function=sum_over,\n",
    "    )\n",
    ")\n",
    "dike_model.outcomes = outcomes\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T20:10:35.611427Z",
     "start_time": "2023-06-20T20:10:35.594306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "598it [01:10,  8.43it/s]                                                       \n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: 'C:\\\\Drive sync\\\\study\\\\Y3\\\\Q4\\\\epa1361_open\\\\final assignment\\\\archives\\\\tmp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mround\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(rounds):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m SequentialEvaluator(dike_model) \u001b[38;5;28;01mas\u001b[39;00m evaluator:\n\u001b[1;32m---> 35\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnfe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msearchover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mepsilons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_scenarios\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mconvergence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvergence_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     experiments\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     42\u001b[0m     convergences\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:248\u001b[0m, in \u001b[0;36mBaseEvaluator.optimize\u001b[1;34m(self, algorithm, nfe, searchover, reference, constraints, convergence_freq, logging_freq, variator, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    232\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mEpsNSGAII,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    241\u001b[0m ):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convenience method for outcome optimization.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    is forwarded to :func:optimize, with evaluator and models\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m    arguments added in.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_msis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnfe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnfe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearchover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearchover\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvergence_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvergence_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:744\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(models, algorithm, nfe, searchover, evaluator, reference, convergence, constraints, convergence_freq, logging_freq, variator, **kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluator:\n\u001b[0;32m    742\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m SequentialEvaluator(models)\n\u001b[1;32m--> 744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvergence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnfe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvergence_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:1102\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(problem, evaluator, algorithm, convergence, nfe, convergence_freq, logging_freq, variator, **kwargs)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# convergence.pbar.__exit__(None, None, None)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m results \u001b[38;5;241m=\u001b[39m to_dataframe(optimizer\u001b[38;5;241m.\u001b[39mresult, problem\u001b[38;5;241m.\u001b[39mparameter_names, problem\u001b[38;5;241m.\u001b[39moutcome_names)\n\u001b[1;32m-> 1102\u001b[0m convergence \u001b[38;5;241m=\u001b[39m \u001b[43mconvergence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimization completed, found \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m solutions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1105\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(optimizer\u001b[38;5;241m.\u001b[39marchive)))\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:851\u001b[0m, in \u001b[0;36mConvergence.to_dataframe\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m     progress \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m:=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    855\u001b[0m     progress \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(progress)\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:852\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    851\u001b[0m     progress \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 852\u001b[0m         metric\u001b[38;5;241m.\u001b[39mname: result \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;28;01mif\u001b[39;00m (result \u001b[38;5;241m:=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    853\u001b[0m     }\n\u001b[0;32m    855\u001b[0m     progress \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(progress)\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[1;32mC:\\Drive sync\\study\\Y3\\Q4\\epa1361_open\\venv\\Lib\\site-packages\\ema_workbench\\em_framework\\optimization.py:699\u001b[0m, in \u001b[0;36mArchiveLogger.get_results\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarfilename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw:gz\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m z:\n\u001b[0;32m    697\u001b[0m     z\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp, arcname\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp))\n\u001b[1;32m--> 699\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:759\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;66;03m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rmtree_unsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:626\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    624\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 626\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\shutil.py:624\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    622\u001b[0m             onerror(os\u001b[38;5;241m.\u001b[39munlink, fullname, sys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 624\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(path)\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     onerror(os\u001b[38;5;241m.\u001b[39mrmdir, path, sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'C:\\\\Drive sync\\\\study\\\\Y3\\\\Q4\\\\epa1361_open\\\\final assignment\\\\archives\\\\tmp'"
     ]
    }
   ],
   "source": [
    "#If done before load results\n",
    "experiment_name = 'first_MOEA'\n",
    "path = experiment_name + '.pickle'\n",
    "done_before = os.path.exists(path)\n",
    "\n",
    "\n",
    "if done_before:\n",
    "    with open(path, 'rb') as file:\n",
    "        experiment_name, convergences = pickle.load(file)\n",
    "else:\n",
    "    #Do experiments\n",
    "#SequentialEvaluator\n",
    "    #MultiprocessingEvaluator\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "    epsilons = [0.2,]*10\n",
    "\n",
    "\n",
    "    convergence_metrics = [ArchiveLogger(\n",
    "                        \"./archives\",\n",
    "                        [l.name for l in dike_model.levers],\n",
    "                        [o.name for o in dike_model.outcomes],\n",
    "                        base_filename=\"tutorial.tar.gz\",\n",
    "                        ), EpsilonProgress()]\n",
    "\n",
    "    constraints = []\n",
    "    for constraint_name in constraint_names:\n",
    "        constraints.append(Constraint(constraint_name, outcome_names=constraint_name,\n",
    "                          function=lambda x: max(0, x - 0.1)))\n",
    "    experiments = []\n",
    "    convergences = []\n",
    "    rounds = 5\n",
    "    for round in range(rounds):\n",
    "        with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "            results = evaluator.optimize(nfe=5e3,\n",
    "                                        searchover='levers',\n",
    "                                        epsilons=epsilons,\n",
    "                                        reference=ref_scenarios[0],\n",
    "                                        convergence=convergence_metrics,\n",
    "                                        constraints=constraints)\n",
    "        experiments.append(results[0])\n",
    "        convergences.append(results[1])\n",
    "    #Save results\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump((experiments, convergences), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archives = ArchiveLogger.load_archives(f\"./archives/tutorial.tar.gz\")\n",
    "reference_set = archives[max(archives.keys())] # this is the final archive\n",
    "\n",
    "metrics = calculate_metrics(archives, reference_set)\n",
    "plot_metrics(metrics, convergence)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = to_problem(dike_model, searchover=\"levers\")\n",
    "reference_set = epsilon_nondominated(results,  epsilons=epsilons, problem=problem)\n",
    "convergence_metrics = [EpsilonProgress(), HypervolumeMetric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archives = ArchiveLogger.load_archives(f\"./archives/tutorial.tar.gz\")\n",
    "reference_set = archives[max(archives.keys())] # this is the final archive\n",
    "\n",
    "metrics = calculate_metrics(archives, reference_set)\n",
    "plot_metrics(metrics, convergence)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T16:44:04.306729Z",
     "start_time": "2023-06-20T16:44:04.162321Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(outcomes.total_expected_cost, outcomes.total_expected_cost_them, outcomes.total_expected_cost_us)\n",
    "ax.set_xlabel('total_expected_cost')\n",
    "ax.set_ylabel('total_expected_cost_them')\n",
    "ax.set_zlabel('total_expected_cost_us')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T16:46:38.927177Z",
     "start_time": "2023-06-20T16:46:38.608017Z"
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "limits = parcoords.get_limits(outcomes)\n",
    "axes = parcoords.ParallelAxes(limits)\n",
    "axes.plot(outcomes)\n",
    "\n",
    "# we invert this axis so direction of desirability is the same\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
